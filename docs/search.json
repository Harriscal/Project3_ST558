[
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Predictive Modeling of Diabetes Status Using Health Indicators",
    "section": "",
    "text": "In this section, we develop classification models to predict whether an individual has diabetes (Diabetes_binary) using health-related predictors from the 2015 BRFSS dataset.\nBased on insights from the exploratory analysis, we focus on predictors such as BMI(Body Mass Index), PhysActivty (Physical Activity), and HighBP (High Blood Pressure). We will evaluate three types of models: logistic regression, classification trees, and random forests.\nAll models are fit using the caret package in R. Model performance is assessed using log loss as the primary evaluation metric, with 5-fold cross-validation applied to select the best configuration within each model type. Final comparisons will be made on a held-out test set."
  },
  {
    "objectID": "Modeling.html#introduction",
    "href": "Modeling.html#introduction",
    "title": "Predictive Modeling of Diabetes Status Using Health Indicators",
    "section": "",
    "text": "In this section, we develop classification models to predict whether an individual has diabetes (Diabetes_binary) using health-related predictors from the 2015 BRFSS dataset.\nBased on insights from the exploratory analysis, we focus on predictors such as BMI(Body Mass Index), PhysActivty (Physical Activity), and HighBP (High Blood Pressure). We will evaluate three types of models: logistic regression, classification trees, and random forests.\nAll models are fit using the caret package in R. Model performance is assessed using log loss as the primary evaluation metric, with 5-fold cross-validation applied to select the best configuration within each model type. Final comparisons will be made on a held-out test set."
  },
  {
    "objectID": "Modeling.html#data-splitting",
    "href": "Modeling.html#data-splitting",
    "title": "Predictive Modeling of Diabetes Status Using Health Indicators",
    "section": "Data Splitting",
    "text": "Data Splitting\n\n#load require libraries \nlibrary(readr)\nlibrary(rsample)\nlibrary(caret)\nlibrary(dplyr)\nlibrary(yardstick)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(randomForest)\nlibrary(ranger)\nlibrary(ModelMetrics)\n\n\n#read in data again (same as EDA.qmd)\ndiabetes &lt;- read_csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\") |&gt;\n  as_tibble() |&gt;\n  mutate(\n    Diabetes_binary = factor(Diabetes_binary, labels = c(\"No\", \"Yes\")),\n    HighBP = factor(HighBP, labels = c(\"No\", \"Yes\")),\n    PhysActivity = factor(PhysActivity, labels = c(\"No\", \"Yes\"))\n  )\n\n#set seed for reproducibility\nset.seed(123)\n\n#split data: 70% training, 30% testing\nsplit &lt;- initial_split(diabetes, prop = 0.7, strata = Diabetes_binary)\ntrain_data &lt;- training(split)\ntest_data &lt;- testing(split)"
  },
  {
    "objectID": "Modeling.html#logistic-regression-models",
    "href": "Modeling.html#logistic-regression-models",
    "title": "Predictive Modeling of Diabetes Status Using Health Indicators",
    "section": "Logistic Regression Models",
    "text": "Logistic Regression Models\nLogistic regression is a classification method used when the response variable is binary. Instead of modeling the response directly, logistic regression models the log-odds (also called the logit) of the outcome as a linear combination of the predictors:\n\\[\\log\\left(\\frac{P(Y = 1)}{1 - P(Y = 1)}\\right) = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p\\]\nThis ensures that the predicted probabilities always lie between 0 and 1, which is a key property when modeling binary outcomes. In this analysis, the response variable is Diabetes_binary, which indicates whether or not an individual has diabetes (Yes or No), making logistic regression a natural and interpretable choice.\nWe use the caret package to fit three candidate logistic regression models using different sets of predictors identified during exploratory analysis. Each model is evaluated using 5-fold cross-validation with log loss as the performance metric. Log loss penalizes incorrect predictions more severely when the model is overconfident, making it especially appropriate when evaluating predicted probabilities rather than simple classifications.\nThe three logistic regression models we fit are:\n\nModel 1: BMI only\n\nModel 2: BMI and High Blood Pressure\n\nModel 3: BMI, High Blood Pressure, and Physical Activity\n\nAll models are fit using caret::train() with method = \"glm\" (for standard logistic regression) and family = binomial. The model with the lowest average log loss across the cross-validation folds is selected as the best model to carry forward.\n\n#define trainControl object for 5-fold CV + log loss\nctrl &lt;- trainControl(\n  method = \"cv\",\n  number = 5,\n  classProbs = TRUE,\n  summaryFunction = mnLogLoss\n)\n\n\n#model 1: BMI only\nlog_model1 &lt;- train(\n  Diabetes_binary ~ BMI,\n  data = train_data,\n  method = \"glm\",\n  family = \"binomial\",\n  trControl = ctrl,\n  metric = \"logLoss\"\n)\n\n#model 2: BMI + HighBP\nlog_model2 &lt;- train(\n  Diabetes_binary ~ BMI + HighBP,\n  data = train_data,\n  method = \"glm\",\n  family = \"binomial\",\n  trControl = ctrl,\n  metric = \"logLoss\"\n)\n\n#model 3: BMI + HighBP + PhysActivity\nlog_model3 &lt;- train(\n  Diabetes_binary ~ BMI + HighBP + PhysActivity,\n  data = train_data,\n  method = \"glm\",\n  family = \"binomial\",\n  trControl = ctrl,\n  metric = \"logLoss\"\n)\n\n\n#display results in a data frame\nmodel_results &lt;- data.frame(\n  Model = c(\"Model 1: BMI\",\n            \"Model 2: BMI + HighBP\",\n            \"Model 3: BMI + HighBP + PhysActivity\"),\n  LogLoss = c(\n    min(log_model1$results$logLoss),\n    min(log_model2$results$logLoss),\n    min(log_model3$results$logLoss)\n  )\n)\n\nmodel_results\n\n                                 Model   LogLoss\n1                         Model 1: BMI 0.3835054\n2                Model 2: BMI + HighBP 0.3569281\n3 Model 3: BMI + HighBP + PhysActivity 0.3548240\n\n\nThe table above summarizes the log loss values for each of the three logistic regression models fit using 5-fold cross-validation.\n\nModel 1, which includes only BMI as a predictor, has the highest log loss (0.384), indicating weaker performance.\nModel 2, which adds HighBP to the model, improves prediction substantially, reducing the log loss to 0.357.\nModel 3, which includes BMI, HighBP, and PhysActivity, achieves the lowest log loss (0.354), suggesting it has the best predictive accuracy of the three.\n\nThus, Model 3 is selected as the best logistic regression model and will be retained for comparison against other model types (e.g., trees and random forests)."
  },
  {
    "objectID": "Modeling.html#classification-tree-models",
    "href": "Modeling.html#classification-tree-models",
    "title": "Predictive Modeling of Diabetes Status Using Health Indicators",
    "section": "Classification Tree Models",
    "text": "Classification Tree Models\nClassification trees are non-linear models that predict a categorical outcome by recursively splitting the predictor space into distinct and homogeneous regions. At each step, the algorithm chooses a predictor and a split point that maximizes class separation (typically using measures like Gini impurity or entropy). The result is a flowchart-like structure where observations are classified based on a sequence of decision rules.\nTrees are appealing because they are easy to interpret and can naturally handle interactions between variables and non-linear relationships. They also do not require assumptions about the distribution of predictors. However, they can be prone to overfitting, which is why pruning the tree (via a complexity parameter, cp) is essential.\nIn this analysis, we fit a classification tree using the rpart method in the caret package. We tune the complexity parameter (cp) using 5-fold cross-validation and select the model that minimizes log loss. The predictors used in the tree are the same as in the best logistic regression model: BMI, High Blood Pressure, and Physical Activity.\n\n#set up 5-fold CV with log loss\nctrl_tree &lt;- trainControl(\n  method = \"cv\",\n  number = 5,\n  classProbs = TRUE,\n  summaryFunction = mnLogLoss\n)\n\n#grid of complexity parameter (cp) values to test\ngrid_tree &lt;- expand.grid(cp = seq(0.001, 0.05, by = 0.005))\n\n#fit classification tree model\nset.seed(101)\ntree_model &lt;- train(\n  Diabetes_binary ~ BMI + HighBP + PhysActivity,\n  data = train_data,\n  method = \"rpart\",\n  trControl = ctrl_tree,\n  metric = \"logLoss\",\n  tuneGrid = grid_tree\n)\n\n# View results\ntree_model$results\n\n      cp   logLoss    logLossSD\n1  0.001 0.4037502 2.511909e-05\n2  0.006 0.4037502 2.511909e-05\n3  0.011 0.4037502 2.511909e-05\n4  0.016 0.4037502 2.511909e-05\n5  0.021 0.4037502 2.511909e-05\n6  0.026 0.4037502 2.511909e-05\n7  0.031 0.4037502 2.511909e-05\n8  0.036 0.4037502 2.511909e-05\n9  0.041 0.4037502 2.511909e-05\n10 0.046 0.4037502 2.511909e-05\n\n\n\n#extract the final tree model from caret object\nfinal_tree &lt;- tree_model$finalModel\n\n#plot the tree\nrpart.plot(final_tree,\n           type = 2,         #type 2 = label all nodes\n           extra = 104,      #shows fitted class + probability + % of obs\n           under = TRUE,     #labels under the box\n           faclen = 0,       #use full names for factor levels\n           main = \"Final Classification Tree for Predicting Diabetes\")\n\n\n\n\n\n\n\n\nThe final classification tree plot above reveals that the model did not split the data at all. where it predicts every observation as ‚ÄúNo‚Äù for diabetes. This outcome is likely due to the strong class imbalance in the training data, where about 86% of observations are non-diabetic.\nThe tuning grid of complexity parameters (cp values) did not affect the model performance, with all configurations resulting in the same log loss of approximately 0.4038. Since no split improved the log loss metric meaningfully, the algorithm defaulted to a root-only tree.\nWhile classification trees are known for being interpretable and modeling interactions well, they can struggle with imbalanced data or when the splits do not provide sufficient gain under the loss function. This outcome suggests that classification trees may not be the best standalone model for this dataset, though they can still be useful within ensemble methods like random forests.\nThe final classification tree was fit using the formula:\n\\[Diabetes\\_binary ‚àº BMI + HighBP + PhysActivity \\] This model included all three predictors identified during the earlier modeling process. However, cross-validation using log-loss as the performance metric revealed that none of the potential splits offered a meaningful improvement. As a result, the optimal tree did not split at all, leading to a very simple stump model that predicts the majority class (‚ÄúNo‚Äù) for all cases. This outcome is reflected in the tree plot and highlights one limitation of basic classification trees: they are prone to underfitting when signal is weak or thresholds are strict."
  },
  {
    "objectID": "Modeling.html#random-forest",
    "href": "Modeling.html#random-forest",
    "title": "Predictive Modeling of Diabetes Status Using Health Indicators",
    "section": "Random Forest",
    "text": "Random Forest\nRandom Forest is an ensemble learning method that builds on the foundation of classification trees. Rather than fitting a single decision tree, a random forest grows many decision trees using random subsets of the data and predictors, and then averages their predictions (for regression) or takes a majority vote (for classification).\nThis approach helps address some of the major weaknesses of a single tree:\n\nTrees are high variance models; a small change in the data can lead to a completely different tree.\nTrees can easily overfit, especially if grown deep.\nRandom Forests mitigate this by averaging results across multiple trees, improving predictive accuracy and stability.\n\nWe also introduce randomness at each tree split (by selecting a random subset of predictors) which helps decorrelate the trees. This improves ensemble performance and is especially useful when predictors are correlated.\nGiven that our classification tree failed to split when using log-loss, a Random Forest may do better by combining many weak learners. We‚Äôll continue using log-loss and 5-fold cross-validation with the caret package, and will tune the number of variables (mtry) tried at each split.\n\n#define the tuning grid for the ranger random forest model\nrf_grid &lt;- expand.grid(\n  mtry = c(1, 2, 3),         #number of predictors considered at each split\n  splitrule = \"gini\",        #use Gini impurity for classification (default)\n  min.node.size = 10         #minimum number of observations in a terminal node (larger = faster)\n)\n\n#set seed for reproducibility\nset.seed(101)\n\n#train the random forest model using caret and ranger\nrf_model &lt;- train(\n  Diabetes_binary ~ BMI + HighBP + PhysActivity,  #model formula\n  data = train_data,                              #training data only\n  method = \"ranger\",                              #use ranger implementation\n  tuneGrid = rf_grid,                             #custom grid of tuning parameters\n  metric = \"logLoss\",                             #evaluation metric for model performance\n  maximize = FALSE,                               #minimize log-loss\n  trControl = trainControl(\n    method = \"cv\",                                #use cross-validation\n    number = 5,                                   #5-fold CV\n    classProbs = TRUE,                            #enable class probabilities for logLoss\n    summaryFunction = mnLogLoss                   #specify custom summary function\n  ),\n  num.trees = 100                                 #reduce number of trees for faster training\n)\n\n#view cross-validation results for each combination of tuning parameters\nrf_model$results\n\n  mtry splitrule min.node.size   logLoss    logLossSD\n1    1      gini            10 0.3565280 0.0009236803\n2    2      gini            10 0.3512141 0.0011844720\n3    3      gini            10 0.3543301 0.0033263844\n\n\nFrom above, the ranger engine was used from the caret package and trained models using 5-fold cross-validation. The log-loss metric was used to evaluate model performance. We set up a tuning grid for the number of predictors sampled at each split (mtry), using values from 1 to 3, since the model includes 3 total predictors.\nAlthough mtry = 2 had the lowest log-loss, its standard deviation was slightly higher than the others. Still, all models performed similarly, and mtry = 2 was selected for the final model due to its superior average performance.\nThe final random forest model was also built using:\n\\[Diabetes\\_binary ‚àº BMI + HighBP + PhysActivity \\]\nThe model was trained using the ranger method with 5-fold cross-validation and log-loss as the performance metric. To improve speed during rendering, we reduced the number of trees to 100 and limited the tuning grid to a few key values for mtry. Despite its complexity and ensemble structure, the model‚Äôs performance on the test set was not superior to the simpler models, which is not uncommon in low-signal or imbalanced classification tasks."
  },
  {
    "objectID": "Modeling.html#final-model-selection",
    "href": "Modeling.html#final-model-selection",
    "title": "Predictive Modeling of Diabetes Status Using Health Indicators",
    "section": "Final Model Selection",
    "text": "Final Model Selection\nNow that we‚Äôve trained and tuned three different model types; logistic regression, classification tree, and random forest. Using cross-validation on the training set, we shift our focus to evaluating their performance on the test set. The ultimate goal is to determine which model best generalizes to new, unseen data.\nEach of the three models was trained using the same set of predictors: BMI, HighBP, and PhysActivity. This allowed for a fair comparison of the modeling approaches themselves while holding the input features constant.\nTo evaluate generalization performance, each model was assessed on the held-out test set using log-loss, which penalizes incorrect and overconfident predictions more heavily than accuracy. The results are summarized below:\n\n#make predictions and evaluate on test set\n\n#logistic Regression (best model was: BMI + HighBP + PhysActivity)\nlog_pred &lt;- predict(log_model3, newdata = test_data, type = \"prob\")[, \"Yes\"]\nlog_loss_log &lt;- logLoss(actual = test_data$Diabetes_binary, predicted = log_pred)\n\n#classification Tree\ntree_pred &lt;- predict(tree_model, newdata = test_data, type = \"prob\")[, \"Yes\"]\nlog_loss_tree &lt;- logLoss(actual = test_data$Diabetes_binary, predicted = tree_pred)\n\n#random Forest\nrf_pred &lt;- predict(rf_model, newdata = test_data, type = \"prob\")[, \"Yes\"]\nlog_loss_rf &lt;- logLoss(actual = test_data$Diabetes_binary, predicted = rf_pred)\n\n#combine and display results\nresults &lt;- tibble(\n  Model = c(\"Logistic Regression\", \"Classification Tree\", \"Random Forest\"),\n  LogLoss = c(log_loss_log, log_loss_tree, log_loss_rf)\n)\n\nresults\n\n# A tibble: 3 √ó 2\n  Model               LogLoss\n  &lt;chr&gt;                 &lt;dbl&gt;\n1 Logistic Regression    2.48\n2 Classification Tree    2.22\n3 Random Forest          2.51\n\n#need to save the final model for the API.R file\nsaveRDS(tree_model, file = \"final_model.rds\")\n\nDespite being the simplest in structure, the Classification Tree achieved the lowest log-loss on the test set. While the tree did not perform splits during training due to lack of signal under cross-validation, it surprisingly generalized better than both logistic regression and random forest in this case.\nThis outcome highlights an important modeling lesson: more complex models do not always lead to better predictions, especially when the predictive signal is weak or the dataset is imbalanced. The classification tree model likely benefitted from conservative predictions that aligned well with the distribution of the test set.\nTherefore, we select the Classification Tree as the final model for predicting diabetes status in this dataset."
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "Exploratory Data Analysis: BRFSS 2015 Diabetes Indicators",
    "section": "",
    "text": "This analysis uses data from the Diabetes Health Indicators Dataset, which originates from the 2015 Behavioral Risk Factor Surveillance System (BRFSS). The dataset contains over 250,000 observations collected via a health-related telephone survey.\nThe response variable is Diabetes_binary, which indicates whether the respondent has been diagnosed with diabetes (1 = Yes, 0 = No). The dataset includes a variety of behavioral and clinical health indicators, such as BMI, blood pressure, cholesterol, physical activity, and smoking status.\nThe purpose of this EDA is to investigate key features in the data and identify potential predictors for diabetes status. We aim to build a predictive model in the next phase of the project.\nFor this exploration, we focus on the following three variables due to their clinical relevance:\n\nBMI(Body Mass Index): A continuous measure of body fat based on height and weight. Higher BMI is strongly associated with obesity, a major risk factor for type 2 diabetes. Investigating BMI helps evaluate how excess weight relates to diabetes prevalence.\nPhysActivity (Physical Activity): A binary variable indicating whether the respondent engaged in physical activity during the past 30 days (1 = Yes, 0 = No). Regular activity improves insulin sensitivity and lowers diabetes risk, making it an important behavioral factor.\nHighBP (High Blood Pressure): A binary variable (1 = Yes, 0 = No) indicating whether the respondent has ever been told they have high blood pressure. Hypertension often co-occurs with diabetes due to shared metabolic risk factors.\n\nThese variables were selected based on strong support in medical literature and public health guidelines as key contributors to diabetes onset and progression. They also represent a mix of lifestyle and clinical health indicators."
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "Exploratory Data Analysis: BRFSS 2015 Diabetes Indicators",
    "section": "",
    "text": "This analysis uses data from the Diabetes Health Indicators Dataset, which originates from the 2015 Behavioral Risk Factor Surveillance System (BRFSS). The dataset contains over 250,000 observations collected via a health-related telephone survey.\nThe response variable is Diabetes_binary, which indicates whether the respondent has been diagnosed with diabetes (1 = Yes, 0 = No). The dataset includes a variety of behavioral and clinical health indicators, such as BMI, blood pressure, cholesterol, physical activity, and smoking status.\nThe purpose of this EDA is to investigate key features in the data and identify potential predictors for diabetes status. We aim to build a predictive model in the next phase of the project.\nFor this exploration, we focus on the following three variables due to their clinical relevance:\n\nBMI(Body Mass Index): A continuous measure of body fat based on height and weight. Higher BMI is strongly associated with obesity, a major risk factor for type 2 diabetes. Investigating BMI helps evaluate how excess weight relates to diabetes prevalence.\nPhysActivity (Physical Activity): A binary variable indicating whether the respondent engaged in physical activity during the past 30 days (1 = Yes, 0 = No). Regular activity improves insulin sensitivity and lowers diabetes risk, making it an important behavioral factor.\nHighBP (High Blood Pressure): A binary variable (1 = Yes, 0 = No) indicating whether the respondent has ever been told they have high blood pressure. Hypertension often co-occurs with diabetes due to shared metabolic risk factors.\n\nThese variables were selected based on strong support in medical literature and public health guidelines as key contributors to diabetes onset and progression. They also represent a mix of lifestyle and clinical health indicators."
  },
  {
    "objectID": "EDA.html#data",
    "href": "EDA.html#data",
    "title": "Exploratory Data Analysis: BRFSS 2015 Diabetes Indicators",
    "section": "Data",
    "text": "Data\nThe dataset was imported using a relative path to ensure compatibility with reproducible workflows. It contains over 250,000 observations and 22 variables collected from the 2015 BRFSS survey. These include binary indicators for health conditions and behaviors, as well as continuous variables like BMI.\nWe began by checking the structure of the data and confirmed that most variables are either binary or categorical, even if numerically encoded.\n\n#load require libraries \nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\n\n#read in the diabetes dataset as a tibble\ndiabetes &lt;- read_csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\") |&gt; \n  as_tibble()\n\n#check structure and dimensions of the dataset\nglimpse(diabetes)\n\nRows: 253,680\nColumns: 22\n$ Diabetes_binary      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0‚Ä¶\n$ HighBP               &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1‚Ä¶\n$ HighChol             &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1‚Ä¶\n$ CholCheck            &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ BMI                  &lt;dbl&gt; 40, 25, 28, 27, 24, 25, 30, 25, 30, 24, 25, 34, 2‚Ä¶\n$ Smoker               &lt;dbl&gt; 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0‚Ä¶\n$ Stroke               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0‚Ä¶\n$ HeartDiseaseorAttack &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ PhysActivity         &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1‚Ä¶\n$ Fruits               &lt;dbl&gt; 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1‚Ä¶\n$ Veggies              &lt;dbl&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1‚Ä¶\n$ HvyAlcoholConsump    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ AnyHealthcare        &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ NoDocbcCost          &lt;dbl&gt; 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0‚Ä¶\n$ GenHlth              &lt;dbl&gt; 5, 3, 5, 2, 2, 2, 3, 3, 5, 2, 3, 3, 3, 4, 4, 2, 3‚Ä¶\n$ MentHlth             &lt;dbl&gt; 18, 0, 30, 0, 3, 0, 0, 0, 30, 0, 0, 0, 0, 0, 30, ‚Ä¶\n$ PhysHlth             &lt;dbl&gt; 15, 0, 30, 0, 0, 2, 14, 0, 30, 0, 0, 30, 15, 0, 2‚Ä¶\n$ DiffWalk             &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0‚Ä¶\n$ Sex                  &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0‚Ä¶\n$ Age                  &lt;dbl&gt; 9, 7, 9, 11, 11, 10, 9, 11, 9, 8, 13, 10, 7, 11, ‚Ä¶\n$ Education            &lt;dbl&gt; 4, 6, 4, 3, 5, 6, 6, 4, 5, 4, 6, 5, 5, 4, 6, 6, 4‚Ä¶\n$ Income               &lt;dbl&gt; 3, 1, 8, 6, 4, 8, 7, 4, 1, 3, 8, 1, 7, 6, 2, 8, 3‚Ä¶\n\ndim(diabetes)\n\n[1] 253680     22\n\n#check for missing values within the data\ncolSums(is.na(diabetes))\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n#summarize number of unique values (helps identify categorical variables)\nsapply(diabetes, n_distinct)\n\n     Diabetes_binary               HighBP             HighChol \n                   2                    2                    2 \n           CholCheck                  BMI               Smoker \n                   2                   84                    2 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   2                    2                    2 \n              Fruits              Veggies    HvyAlcoholConsump \n                   2                    2                    2 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   2                    2                    5 \n            MentHlth             PhysHlth             DiffWalk \n                  31                   31                    2 \n                 Sex                  Age            Education \n                   2                   13                    6 \n              Income \n                   8 \n\n#convert selected binary variables to factors for easier interpretation\ndiabetes &lt;- diabetes |&gt; \n  mutate(\n    Diabetes_binary = factor(Diabetes_binary, labels = c(\"No\", \"Yes\")),\n    HighBP = factor(HighBP, labels = c(\"No\", \"Yes\")),\n    PhysActivity = factor(PhysActivity, labels = c(\"No\", \"Yes\"))\n  )\n\nFrom above, to identify which variables to treat as factors, we computed the number of unique values per column. Most variables had only two distinct values, supporting their interpretation as binary indicators. A few variables like BMI, Age, Income, and self-reported health (GenHlth, PhysHlth, MentHlth) had multiple levels and were left as numeric or ordinal as appropriate.\nNo missing values were detected, and variable names are consistent with those provided in the Kaggle documentation. To improve interpretability during EDA, we converted the selected binary variables (Diabetes_binary, HighBP, and PhysActivity) used for the following analysis into factors with meaningful labels."
  },
  {
    "objectID": "EDA.html#summarizations",
    "href": "EDA.html#summarizations",
    "title": "Exploratory Data Analysis: BRFSS 2015 Diabetes Indicators",
    "section": "Summarizations",
    "text": "Summarizations\n\nUnivariate Summaries\n\n#Diabetes_binary (response)\ndiabetes |&gt;\n  count(Diabetes_binary) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 2 √ó 3\n  Diabetes_binary      n  prop\n  &lt;fct&gt;            &lt;int&gt; &lt;dbl&gt;\n1 No              218334 0.861\n2 Yes              35346 0.139\n\n#BMI\nsummary(diabetes$BMI)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  12.00   24.00   27.00   28.38   31.00   98.00 \n\n#BMI histogram\ndiabetes |&gt; \nggplot(aes(x = BMI)) +\n  geom_histogram(bins = 30, fill = \"#69b3a2\", color = \"white\") +\n  labs(title = \"Distribution of BMI (Body Mass Index)\",\n       x = \"BMI\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n#HighBP\ndiabetes |&gt;\n  count(HighBP) |&gt; \n  mutate(prop = n / sum(n))\n\n# A tibble: 2 √ó 3\n  HighBP      n  prop\n  &lt;fct&gt;   &lt;int&gt; &lt;dbl&gt;\n1 No     144851 0.571\n2 Yes    108829 0.429\n\n#PhysActivity\ndiabetes |&gt; \n  count(PhysActivity) |&gt; \n  mutate(prop = n / sum(n))\n\n# A tibble: 2 √ó 3\n  PhysActivity      n  prop\n  &lt;fct&gt;         &lt;int&gt; &lt;dbl&gt;\n1 No            61760 0.243\n2 Yes          191920 0.757\n\n\nFrom the summaries:\n\nDiabetes Status (Diabetes_binary): About 13.9% of individuals reported having diabetes, while the remaining 86.1% did not. This distribution is important for model development, as the outcome is moderately imbalanced.\nBMI (BMI): The mean BMI is 28.38, with a median of 27.00. The values range from 12 to 98, with a right-skewed distribution. This suggests a considerable portion of individuals fall in the overweight or obese category.\nHigh Blood Pressure (HighBP): Roughly 42.9% of the sample reported having high blood pressure, while 57.1% did not. This aligns with expectations, as hypertension often co-occurs with metabolic disorders.\nPhysical Activity (PhysActivity): A majority, 75.7%, reported engaging in some form of physical activity in the past 30 days. The remaining 24.3% were physically inactive, a potential risk factor for chronic disease.\n\n\n\nBivariate Summaries with Diabetes_binary\n\n#BMI by Diabetes status\ndiabetes |&gt; \n  group_by(Diabetes_binary) |&gt; \n  summarise(mean_BMI = mean(BMI), sd_BMI = sd(BMI))\n\n# A tibble: 2 √ó 3\n  Diabetes_binary mean_BMI sd_BMI\n  &lt;fct&gt;              &lt;dbl&gt;  &lt;dbl&gt;\n1 No                  27.8   6.29\n2 Yes                 31.9   7.36\n\n#boxplot: BMI by diabetes status\ndiabetes |&gt; \n  ggplot(aes(x = Diabetes_binary, y = BMI, fill = Diabetes_binary)) +\n  geom_boxplot(outlier.shape = 1, outlier.color = \"black\") +\n  scale_fill_manual(values = c(\"red\", \"blue\")) +\n  labs(title = \"BMI Distribution by Diabetes Status\",\n       x = \"Diabetes Diagnosis\", y = \"BMI\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n#bar plots: Diabetes status vs each categorical predictor\n\n#proportion of Diabetes by HighBP\n\n#reorder factor + sort data so \"Yes\" (blue) is on bottom and \"No\" (red) on top\nprop_highbp &lt;- diabetes |&gt;\n  count(HighBP, Diabetes_binary) |&gt;\n  group_by(HighBP) |&gt;\n  arrange(HighBP, Diabetes_binary) |&gt;\n  mutate(\n    prop = n / sum(n),\n    label_pos = percent(prop, accuracy = 0.1)\n  )\n\n#plot with centered percent labels in the right box\nprop_highbp |&gt; \n  ggplot(aes(x = HighBP, y = prop, fill = Diabetes_binary)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = label_pos),\n            position = position_stack(vjust = 0.5),\n            size = 3, color = \"white\", fontface = \"bold\") +\n  scale_fill_manual(values = c(\"Yes\" = \"blue\", \"No\" = \"red\"),\n                    name = \"Diabetes Status\") +\n  labs(title = \"Proportion of Diabetes by High Blood Pressure\",\n       y = \"Proportion\", x = \"High Blood Pressure Status\") +\n  theme_minimal()\n\n\n\n\n\n\n\n#proportion of Diabetes by Physical Activity\n\n#reorder factor + sort data so \"Yes\" (blue) is on bottom and \"No\" (red) on top\nprop_pa &lt;- diabetes |&gt;\n  count(PhysActivity, Diabetes_binary) |&gt;\n  group_by(PhysActivity) |&gt;\n  arrange(PhysActivity, Diabetes_binary) |&gt;\n  mutate(\n    prop = n / sum(n),\n    label_pos = percent(prop, accuracy = 0.1)\n  )\n\nprop_pa |&gt; \n  ggplot(aes(x = PhysActivity, y = prop, fill = Diabetes_binary)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = label_pos),\n            position = position_stack(vjust = 0.5),\n            size = 3, color = \"white\", fontface = \"bold\") +\n  scale_fill_manual(values = c(\"Yes\" = \"blue\", \"No\" = \"red\"),\n                    name = \"Diabetes Status\") +\n  labs(title = \"Proportion of Diabetes by Physical Activity\",\n       y = \"Proportion\", x = \"Physical Activity in Past 30 Days\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFrom the summaries:\n\nBMI by Diabetes Status: Individuals with diabetes have a higher average BMI, 31.9, than those without diabetes, 27.8.This supports the observed positive relationship between body weight and diabetes.\nProportion of Diabetes by High Blood Pressure: Among individuals with high blood pressure,24.4% have diabetes. In contrast, only 6.0% of those without high blood pressure have diabetes. This highlights a strong positive association between hypertension and diabetes risk.\nProportion of Diabetes by Physical Activity: Only 11.6% of individuals who reported physical activity had diabetes, compared to 21.1% among those who were inactive. This suggests a potential protective effect of regular activity against diabetes onset."
  },
  {
    "objectID": "EDA.html#next-steps",
    "href": "EDA.html#next-steps",
    "title": "Exploratory Data Analysis: BRFSS 2015 Diabetes Indicators",
    "section": "Next Steps",
    "text": "Next Steps\nHaving explored the univariate distributions and bivariate relationships between predictors and diabetes status, we now proceed to develop predictive models using these variables.\nüëâ Click here to continue to the Modeling page"
  }
]